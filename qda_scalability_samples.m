% QDA scalability based on the count of samples. % The count of features is kept constant.% We measure runtime of model training and scoring of the training data. % Once for the model from scratch. Once with incremental learning.% Result: The Model scales linearly. I can process 1 million rows per second.%   runtime =  10e-06*x + 0.02% Setting (the maximal matrix I can process is ~20k x 10k)nrow_max = 100000;ncol = 1000;% Initializationlogger_x = [];logger_scratch = [];logger_incremental = [];x = randn(nrow_max, ncol);y = 1 + (rand(nrow_max, 1)>0.5);for nrow=2500:500:nrow_max    % Data preparation for incremental versions    x1 = x(1:nrow,1:end-1);    x2 = x(1:nrow,end);    y_subset = y(1:nrow);    % Measure runtime of QDA from scratch    % It has a tiny advantage by working on the matrix without the new feature     tic;    [~, new_struct] = qda_chol_incremental(x1, y_subset);    logger_scratch = [logger_scratch, toc]        tic;    obtained = qda_chol_incremental(x2, y_subset, new_struct);    logger_incremental = [logger_incremental, toc];        logger_x = [logger_x, nrow];end%% Plotclfplot(logger_x, logger_scratch, 'b.:', 'linewidth', 1, 'markerSize', 20)hold onplot(logger_x, logger_incremental, 'r.-', 'linewidth', 1, 'markerSize', 20)title('Training and scoring time for 1000 features')xlabel('Samples')ylabel('Runtime [s]')legend('From scratch', 'Insert', 'location', 'northwest')set(gcf, 'PaperPosition', [0 0.05 5 3]); %Position the plot further to the left and down. Extend the plot to fill entire paper.set(gcf, 'PaperSize', [5 3.05]); %Keep the same paper sizesaveas(gcf, 'scalability_samples.pdf', 'pdf')